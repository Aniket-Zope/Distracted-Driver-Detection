{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IPML Project: Implementing CNN model from scratch","metadata":{}},{"cell_type":"markdown","source":"# Creating Custom CNN (VR-Net)","metadata":{}},{"cell_type":"code","source":"# Importing necessary libraries\nimport os\nimport pandas as pd\nimport pickle\nimport numpy as np\nimport seaborn as sns\nimport secrets\nimport cv2\nfrom PIL import Image\nfrom PIL import ImageFile\nfrom sklearn.datasets import load_files\nfrom keras.utils import np_utils\nimport matplotlib.pyplot as plt\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.models import Sequential\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils import to_categorical\nfrom sklearn.metrics import confusion_matrix\nfrom keras.preprocessing import image                  \nfrom tqdm import tqdm\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:18:04.721169Z","iopub.execute_input":"2023-05-05T12:18:04.721853Z","iopub.status.idle":"2023-05-05T12:18:13.293203Z","shell.execute_reply.started":"2023-05-05T12:18:04.721818Z","shell.execute_reply":"2023-05-05T12:18:13.292072Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Saving the path for train data\ntrainDir = \"/kaggle/input/c/state-farm-distracted-driver-detection/imgs/train\"\ntestDir = \"/kaggle/input/c/state-farm-distracted-driver-detection/imgs/test\"\n# Saving the path for models\nmodelPath = \"/kaggle/working/model\"\n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:18:13.295299Z","iopub.execute_input":"2023-05-05T12:18:13.296114Z","iopub.status.idle":"2023-05-05T12:18:13.301283Z","shell.execute_reply.started":"2023-05-05T12:18:13.296073Z","shell.execute_reply":"2023-05-05T12:18:13.300233Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing the data","metadata":{}},{"cell_type":"code","source":"def increaseBrightness(img, value):\n    # Converting BGR to HSV space\n    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    \n    # Splitting into individual channels as we need to deal with brightness i.e. \"v\"\n    h, s, v = cv2.split(hsv)\n\n    # Just making sure the value doesn't exceed the limit i.e. 255\n    lim = 255 - value\n    \n    v[v > lim] = 255\n    v[v <= lim] += value\n\n    final_hsv = cv2.merge((h, s, v))\n    \n    # Converting it back to BGR\n    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n    return img","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:18:13.302886Z","iopub.execute_input":"2023-05-05T12:18:13.303558Z","iopub.status.idle":"2023-05-05T12:18:13.317798Z","shell.execute_reply.started":"2023-05-05T12:18:13.303518Z","shell.execute_reply":"2023-05-05T12:18:13.316780Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def changeContrast(img, level):\n    # Converting image to PIL object\n    img = Image.fromarray(img.astype('uint8'))\n    # Calculationg a factor.\n    # Multipled by 259 so as to scale the value in the range 0-255\n    # Ensures that the pixel values are not clipped, and the full range of 0-255 is used.\n    \n    # (From grayscale to RBG when multipled by 255 can clip pixels if contrast is high)\n    # Thus using maximum value that can be obtained from the formula\n    # Y = 0.299 * 255 + 0.587 * 255 + 0.114 * 255 = 259\n    factor = (259 * (level + 255)) / (255 * (259 - level))\n    \n    # Helper function - applying contrast to every pixel\n    def contrast(c):\n        return int(128 + factor * (c - 128))\n    return np.array(img.point(contrast))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:18:14.803085Z","iopub.execute_input":"2023-05-05T12:18:14.805735Z","iopub.status.idle":"2023-05-05T12:18:14.813055Z","shell.execute_reply.started":"2023-05-05T12:18:14.805694Z","shell.execute_reply":"2023-05-05T12:18:14.811942Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def preprocessImg(img):\n    img = np.array(img)\n\n    # Randomly setting the order of operations.\n    x = secrets.randbelow(2)\n\n    if x == 0:\n        #Order 01\n        img = increaseBrightness(img, secrets.randbelow(26))\n        img = changeContrast(img, secrets.randbelow(51))\n    else:\n        #Order 02\n        img = changeContrast(img, secrets.randbelow(51))\n        img = increaseBrightness(img, secrets.randbelow(26))\n\n    # Convert the pixel values back to integer format\n    # img = img.astype(np.uint8)\n    return img","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:18:16.607860Z","iopub.execute_input":"2023-05-05T12:18:16.608568Z","iopub.status.idle":"2023-05-05T12:18:16.614906Z","shell.execute_reply.started":"2023-05-05T12:18:16.608531Z","shell.execute_reply":"2023-05-05T12:18:16.613789Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install split-folders","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:18:25.579189Z","iopub.execute_input":"2023-05-05T12:18:25.581314Z","iopub.status.idle":"2023-05-05T12:18:36.130793Z","shell.execute_reply.started":"2023-05-05T12:18:25.581266Z","shell.execute_reply":"2023-05-05T12:18:36.129415Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting split-folders\n  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\nInstalling collected packages: split-folders\nSuccessfully installed split-folders-0.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import splitfolders\n\nmydata = '/kaggle/input/state-farm-distracted-driver-detection/imgs/train'\nsplitfolders.ratio(mydata, output=\"mydata\",\n    seed=1337, ratio=(.7, .1, .2), group_prefix=None, move=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:18:36.133097Z","iopub.execute_input":"2023-05-05T12:18:36.133419Z","iopub.status.idle":"2023-05-05T12:20:32.403547Z","shell.execute_reply.started":"2023-05-05T12:18:36.133388Z","shell.execute_reply":"2023-05-05T12:20:32.400444Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Copying files: 22424 files [01:56, 192.91 files/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train = '/kaggle/working/mydata/train'\nval = '/kaggle/working/mydata/val'\ntest = '/kaggle/working/mydata/test'","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:20:32.405446Z","iopub.execute_input":"2023-05-05T12:20:32.405811Z","iopub.status.idle":"2023-05-05T12:20:32.413027Z","shell.execute_reply.started":"2023-05-05T12:20:32.405774Z","shell.execute_reply":"2023-05-05T12:20:32.411939Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# from keras.preprocessing.image import ImageDataGenerator\n\n# train_datagen = ImageDataGenerator(rescale=1./255)\n# test_datagen = ImageDataGenerator(rescale=1./255)\n\n# batch_size = 128\n\n# train_generator = train_datagen.flow_from_directory(\n#         train,\n#         target_size=(256, 256),\n#         batch_size=128)\n\n# validation_generator = test_datagen.flow_from_directory(\n#         val,\n#         target_size=(256, 256),\n#         batch_size=128)\n     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Initialise the parameters for Augmentation.\n\n# Change RGB to Gray scale there is a parameter\n# Also don't augment validation data.\n# Also see for Batch Normalization\n\ndatagen = ImageDataGenerator(\n        rotation_range = 5,\n        width_shift_range = 0.02,\n        height_shift_range = 0.02,\n        shear_range = 0.01,\n        zoom_range = 0.05,\n        horizontal_flip = False,\n        fill_mode = \"nearest\",\n        validation_split = 0.2,\n#         color_mode=\"grayscale\",\n        preprocessing_function = preprocessImg)\n\ndatagen_test = ImageDataGenerator(\n    preprocessing_function= preprocessImg\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:20:32.415725Z","iopub.execute_input":"2023-05-05T12:20:32.416126Z","iopub.status.idle":"2023-05-05T12:20:32.430936Z","shell.execute_reply.started":"2023-05-05T12:20:32.416081Z","shell.execute_reply":"2023-05-05T12:20:32.429845Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_data = datagen.flow_from_directory(train,\n                                        target_size=(224,224), # Image size\n                                        batch_size=128, # Batch size\n                                        shuffle=True,\n                                        class_mode='sparse')\n\nvalid_data = datagen_test.flow_from_directory(val,\n                                        target_size=(224,224),\n                                        batch_size=128,\n                                        shuffle=True,\n                                        class_mode='sparse')\ntest_data = datagen_test.flow_from_directory(test,\n                                        target_size=(224,224),\n                                        batch_size=128,\n                                        shuffle=True,\n                                        class_mode='sparse')","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:20:32.432453Z","iopub.execute_input":"2023-05-05T12:20:32.433468Z","iopub.status.idle":"2023-05-05T12:20:33.211200Z","shell.execute_reply.started":"2023-05-05T12:20:32.433434Z","shell.execute_reply":"2023-05-05T12:20:33.210234Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Found 15692 images belonging to 10 classes.\nFound 2237 images belonging to 10 classes.\nFound 4495 images belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(valid_data[0][0][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape=(224,224,3)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:21:00.031919Z","iopub.execute_input":"2023-05-05T12:21:00.033029Z","iopub.status.idle":"2023-05-05T12:21:00.038839Z","shell.execute_reply.started":"2023-05-05T12:21:00.032983Z","shell.execute_reply":"2023-05-05T12:21:00.037754Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Lambda\nmodel = Sequential()\n\n# model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(224,224,3), kernel_initializer='glorot_normal'))\nmodel.add(Lambda(lambda x: tf.image.rgb_to_grayscale(x), input_shape=input_shape))  # convert input images to grayscale\n\nmodel.add(Conv2D(16, (5, 5), strides=(2, 2), padding='valid', activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))# add stride 2 to the MaxPooling2D layer\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(Conv2D(16, (3, 3), strides=(2, 2), padding='valid', activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(Conv2D(32, (3, 3), strides=(2, 2), padding='valid', activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\nmodel.add(tf.keras.layers.Dropout(0.3))\n#model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='valid', activation='relu'))\n#model.add(MaxPooling2D((2, 2), strides=(1, 1)))\nmodel.add(Flatten())\n# Checking this inference section\n#model.add(Dense(1024, activation='relu'))\n#model.add(Dense(512, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(Dense(10, activation='softmax'))\n\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:21:01.499861Z","iopub.execute_input":"2023-05-05T12:21:01.500800Z","iopub.status.idle":"2023-05-05T12:21:01.769029Z","shell.execute_reply.started":"2023-05-05T12:21:01.500762Z","shell.execute_reply":"2023-05-05T12:21:01.768219Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lambda (Lambda)             (None, 224, 224, 1)       0         \n                                                                 \n conv2d (Conv2D)             (None, 110, 110, 16)      416       \n                                                                 \n batch_normalization (BatchN  (None, 110, 110, 16)     64        \n ormalization)                                                   \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 55, 55, 16)       0         \n )                                                               \n                                                                 \n dropout (Dropout)           (None, 55, 55, 16)        0         \n                                                                 \n conv2d_1 (Conv2D)           (None, 27, 27, 16)        2320      \n                                                                 \n batch_normalization_1 (Batc  (None, 27, 27, 16)       64        \n hNormalization)                                                 \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 13, 13, 16)       0         \n 2D)                                                             \n                                                                 \n dropout_1 (Dropout)         (None, 13, 13, 16)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 6, 6, 32)          4640      \n                                                                 \n batch_normalization_2 (Batc  (None, 6, 6, 32)         128       \n hNormalization)                                                 \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 3, 3, 32)         0         \n 2D)                                                             \n                                                                 \n dropout_2 (Dropout)         (None, 3, 3, 32)          0         \n                                                                 \n flatten (Flatten)           (None, 288)               0         \n                                                                 \n dense (Dense)               (None, 64)                18496     \n                                                                 \n batch_normalization_3 (Batc  (None, 64)               256       \n hNormalization)                                                 \n                                                                 \n dropout_3 (Dropout)         (None, 64)                0         \n                                                                 \n dense_1 (Dense)             (None, 10)                650       \n                                                                 \n=================================================================\nTotal params: 27,034\nTrainable params: 26,778\nNon-trainable params: 256\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.sparse_categorical_crossentropy,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:21:03.896386Z","iopub.execute_input":"2023-05-05T12:21:03.896820Z","iopub.status.idle":"2023-05-05T12:21:03.916511Z","shell.execute_reply.started":"2023-05-05T12:21:03.896785Z","shell.execute_reply":"2023-05-05T12:21:03.915580Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"filepath = os.path.join(modelPath,\"distracted-{epoch:02d}-{val_accuracy:.2f}.hdf5\")\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:21:05.879177Z","iopub.execute_input":"2023-05-05T12:21:05.879541Z","iopub.status.idle":"2023-05-05T12:21:05.886271Z","shell.execute_reply.started":"2023-05-05T12:21:05.879509Z","shell.execute_reply":"2023-05-05T12:21:05.885163Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model_history = model.fit(train_data,validation_data = valid_data,epochs=20,shuffle=True,callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:21:10.634683Z","iopub.execute_input":"2023-05-05T12:21:10.635066Z","iopub.status.idle":"2023-05-05T13:34:28.513197Z","shell.execute_reply.started":"2023-05-05T12:21:10.635017Z","shell.execute_reply":"2023-05-05T13:34:28.510481Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2023-05-05 12:21:14.303187: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"123/123 [==============================] - ETA: 0s - loss: 2.7117 - accuracy: 0.1321\nEpoch 1: val_accuracy improved from -inf to 0.21681, saving model to /kaggle/working/model/distracted-01-0.22.hdf5\n123/123 [==============================] - 268s 2s/step - loss: 2.7117 - accuracy: 0.1321 - val_loss: 2.1898 - val_accuracy: 0.2168\nEpoch 2/20\n123/123 [==============================] - ETA: 0s - loss: 2.2457 - accuracy: 0.2146\nEpoch 2: val_accuracy improved from 0.21681 to 0.37237, saving model to /kaggle/working/model/distracted-02-0.37.hdf5\n123/123 [==============================] - 259s 2s/step - loss: 2.2457 - accuracy: 0.2146 - val_loss: 1.7906 - val_accuracy: 0.3724\nEpoch 3/20\n123/123 [==============================] - ETA: 0s - loss: 1.9232 - accuracy: 0.3165\nEpoch 3: val_accuracy improved from 0.37237 to 0.43630, saving model to /kaggle/working/model/distracted-03-0.44.hdf5\n123/123 [==============================] - 263s 2s/step - loss: 1.9232 - accuracy: 0.3165 - val_loss: 1.6697 - val_accuracy: 0.4363\nEpoch 4/20\n123/123 [==============================] - ETA: 0s - loss: 1.6990 - accuracy: 0.4037\nEpoch 4: val_accuracy improved from 0.43630 to 0.55208, saving model to /kaggle/working/model/distracted-04-0.55.hdf5\n123/123 [==============================] - 260s 2s/step - loss: 1.6990 - accuracy: 0.4037 - val_loss: 1.3518 - val_accuracy: 0.5521\nEpoch 5/20\n123/123 [==============================] - ETA: 0s - loss: 1.5562 - accuracy: 0.4472\nEpoch 5: val_accuracy improved from 0.55208 to 0.62584, saving model to /kaggle/working/model/distracted-05-0.63.hdf5\n123/123 [==============================] - 260s 2s/step - loss: 1.5562 - accuracy: 0.4472 - val_loss: 1.1258 - val_accuracy: 0.6258\nEpoch 6/20\n123/123 [==============================] - ETA: 0s - loss: 1.4425 - accuracy: 0.4941\nEpoch 6: val_accuracy improved from 0.62584 to 0.65445, saving model to /kaggle/working/model/distracted-06-0.65.hdf5\n123/123 [==============================] - 261s 2s/step - loss: 1.4425 - accuracy: 0.4941 - val_loss: 1.0345 - val_accuracy: 0.6544\nEpoch 7/20\n123/123 [==============================] - ETA: 0s - loss: 1.3565 - accuracy: 0.5246\nEpoch 7: val_accuracy did not improve from 0.65445\n123/123 [==============================] - 266s 2s/step - loss: 1.3565 - accuracy: 0.5246 - val_loss: 1.3908 - val_accuracy: 0.5270\nEpoch 8/20\n123/123 [==============================] - ETA: 0s - loss: 1.2796 - accuracy: 0.5548\nEpoch 8: val_accuracy improved from 0.65445 to 0.72463, saving model to /kaggle/working/model/distracted-08-0.72.hdf5\n123/123 [==============================] - 265s 2s/step - loss: 1.2796 - accuracy: 0.5548 - val_loss: 0.8808 - val_accuracy: 0.7246\nEpoch 9/20\n123/123 [==============================] - ETA: 0s - loss: 1.2180 - accuracy: 0.5827\nEpoch 9: val_accuracy improved from 0.72463 to 0.73938, saving model to /kaggle/working/model/distracted-09-0.74.hdf5\n123/123 [==============================] - 269s 2s/step - loss: 1.2180 - accuracy: 0.5827 - val_loss: 0.8382 - val_accuracy: 0.7394\nEpoch 10/20\n123/123 [==============================] - ETA: 0s - loss: 1.1561 - accuracy: 0.6032\nEpoch 10: val_accuracy improved from 0.73938 to 0.78319, saving model to /kaggle/working/model/distracted-10-0.78.hdf5\n123/123 [==============================] - 266s 2s/step - loss: 1.1561 - accuracy: 0.6032 - val_loss: 0.7220 - val_accuracy: 0.7832\nEpoch 11/20\n123/123 [==============================] - ETA: 0s - loss: 1.1221 - accuracy: 0.6141\nEpoch 11: val_accuracy improved from 0.78319 to 0.80286, saving model to /kaggle/working/model/distracted-11-0.80.hdf5\n123/123 [==============================] - 273s 2s/step - loss: 1.1221 - accuracy: 0.6141 - val_loss: 0.6594 - val_accuracy: 0.8029\nEpoch 12/20\n123/123 [==============================] - ETA: 0s - loss: 1.0453 - accuracy: 0.6387\nEpoch 12: val_accuracy did not improve from 0.80286\n123/123 [==============================] - 264s 2s/step - loss: 1.0453 - accuracy: 0.6387 - val_loss: 0.6421 - val_accuracy: 0.7984\nEpoch 13/20\n123/123 [==============================] - ETA: 0s - loss: 1.0114 - accuracy: 0.6581\nEpoch 13: val_accuracy improved from 0.80286 to 0.82208, saving model to /kaggle/working/model/distracted-13-0.82.hdf5\n123/123 [==============================] - 262s 2s/step - loss: 1.0114 - accuracy: 0.6581 - val_loss: 0.5641 - val_accuracy: 0.8221\nEpoch 14/20\n123/123 [==============================] - ETA: 0s - loss: 0.9775 - accuracy: 0.6674\nEpoch 14: val_accuracy did not improve from 0.82208\n123/123 [==============================] - 262s 2s/step - loss: 0.9775 - accuracy: 0.6674 - val_loss: 0.5742 - val_accuracy: 0.8163\nEpoch 15/20\n123/123 [==============================] - ETA: 0s - loss: 0.9394 - accuracy: 0.6754\nEpoch 15: val_accuracy improved from 0.82208 to 0.86097, saving model to /kaggle/working/model/distracted-15-0.86.hdf5\n123/123 [==============================] - 263s 2s/step - loss: 0.9394 - accuracy: 0.6754 - val_loss: 0.4824 - val_accuracy: 0.8610\nEpoch 16/20\n123/123 [==============================] - ETA: 0s - loss: 0.9011 - accuracy: 0.6926\nEpoch 16: val_accuracy improved from 0.86097 to 0.87930, saving model to /kaggle/working/model/distracted-16-0.88.hdf5\n123/123 [==============================] - 265s 2s/step - loss: 0.9011 - accuracy: 0.6926 - val_loss: 0.4322 - val_accuracy: 0.8793\nEpoch 17/20\n 82/123 [===================>..........] - ETA: 1:22 - loss: 0.8665 - accuracy: 0.7053","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/1608659284.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\nax1.plot(model_history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(model_history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, 25, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(model_history.history['accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(model_history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, 25, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T13:34:34.296095Z","iopub.execute_input":"2023-05-05T13:34:34.297104Z","iopub.status.idle":"2023-05-05T13:34:34.667517Z","shell.execute_reply.started":"2023-05-05T13:34:34.297037Z","shell.execute_reply":"2023-05-05T13:34:34.665996Z"},"trusted":true},"execution_count":18,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/445708419.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model_history' is not defined"],"ename":"NameError","evalue":"name 'model_history' is not defined","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x1200 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"model.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T13:37:22.162178Z","iopub.execute_input":"2023-05-05T13:37:22.163229Z","iopub.status.idle":"2023-05-05T13:37:58.251100Z","shell.execute_reply.started":"2023-05-05T13:37:22.163189Z","shell.execute_reply":"2023-05-05T13:37:58.250115Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"36/36 [==============================] - 35s 969ms/step - loss: 0.4588 - accuracy: 0.8614\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[0.458822637796402, 0.8614015579223633]"},"metadata":{}}]},{"cell_type":"code","source":"num_samples = test_data.samples\nbatch_size = test_data.batch_size\n\n# Initialize empty arrays to store X_test and y_test\nX_test = np.empty(shape=(num_samples, 224, 224, 3), dtype=np.float32)\ny_test = np.empty(shape=(num_samples,), dtype=np.int32)\n\n# Loop through all batches in the test set and concatenate the results\nfor i in range(num_samples // batch_size + 1):\n    batch_X, batch_y = test_data.next()\n    start_idx = i * batch_size\n    end_idx = min(start_idx + batch_size, num_samples)\n    X_test[start_idx:end_idx] = batch_X\n    y_test[start_idx:end_idx] = batch_y.ravel()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T13:35:02.090466Z","iopub.execute_input":"2023-05-05T13:35:02.091462Z","iopub.status.idle":"2023-05-05T13:35:29.503565Z","shell.execute_reply.started":"2023-05-05T13:35:02.091425Z","shell.execute_reply":"2023-05-05T13:35:29.502263Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T13:35:39.127560Z","iopub.execute_input":"2023-05-05T13:35:39.128239Z","iopub.status.idle":"2023-05-05T13:35:46.944590Z","shell.execute_reply.started":"2023-05-05T13:35:39.128199Z","shell.execute_reply":"2023-05-05T13:35:46.943537Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"141/141 [==============================] - 2s 15ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred1 = np.argmax(y_pred,axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T13:37:02.180119Z","iopub.execute_input":"2023-05-05T13:37:02.180840Z","iopub.status.idle":"2023-05-05T13:37:02.186670Z","shell.execute_reply.started":"2023-05-05T13:37:02.180805Z","shell.execute_reply":"2023-05-05T13:37:02.185362Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n \ncm1 = confusion_matrix(y_test, y_pred1)\nprint(cm1)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T13:37:04.226944Z","iopub.execute_input":"2023-05-05T13:37:04.228111Z","iopub.status.idle":"2023-05-05T13:37:04.237618Z","shell.execute_reply.started":"2023-05-05T13:37:04.228041Z","shell.execute_reply":"2023-05-05T13:37:04.236330Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"[[406  11  13  38  19   0   5   1   0   6]\n [  0 435  14   4   2   0   0   0   0   0]\n [  0   2 452   1   1   0   8   0   1   0]\n [  1   2   1 462   3   0   0   0   0   1]\n [  4   1  21  10 420   0   6   0   1   3]\n [  6   0   3   2   3 444   4   0   1   0]\n [  2  17  20   1   0   0 424   0   1   1]\n [  1   9  20   0   1   0   1 368   1   0]\n [ 12  16  63   5  10   0  42  20 213   2]\n [ 70  14  20  18  24  15   3   9  10 244]]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred1)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T13:42:14.706503Z","iopub.execute_input":"2023-05-05T13:42:14.707491Z","iopub.status.idle":"2023-05-05T13:42:14.718193Z","shell.execute_reply.started":"2023-05-05T13:42:14.707450Z","shell.execute_reply":"2023-05-05T13:42:14.716590Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"0.860511679644049"},"metadata":{}}]}]}